{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Features and create labels from the audio files \n",
    "\n",
    "def extract_feature(file_path,sample_rate=22050):\n",
    "    audio, sr = librosa.load(file_path,sr=sample_rate)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr= sr,n_mfcc=13)\n",
    "    chroma = librosa.feature.chroma_stft(y=audio,sr = sr)\n",
    "    mel = librosa.feature.melspectrogram(y=audio, sr = sr)\n",
    "    contrast = librosa.feature.spectral_contrast(y=audio,sr=sr)\n",
    "    tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(audio),sr=sr)\n",
    "    \n",
    "    features = np.hstack([\n",
    "                          np.mean(mfccs, axis=1), \n",
    "                          np.mean(chroma, axis=1), \n",
    "                          np.mean(mel, axis=1), \n",
    "                          np.mean(contrast, axis=1), \n",
    "                          np.mean(tonnetz, axis=1)\n",
    "    ])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAF_disgust\n",
      "OAF_Pleasant_surprise\n",
      ".DS_Store\n",
      "OAF_happy\n",
      "YAF_sad\n",
      "YAF_happy\n",
      "YAF_neutral\n",
      "OAF_Fear\n",
      "OAF_angry\n",
      "YAF_pleasant_surprised\n",
      "YAF_fear\n",
      "OAF_neutral\n",
      "OAF_disgust\n",
      "YAF_angry\n",
      "OAF_Sad\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset(directory,sample_rate=22050):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for folder in os.listdir(directory):\n",
    "        print(folder)\n",
    "        folder_path = os.path.join(directory,folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                feature = extract_feature(file_path,sample_rate)\n",
    "                features.append(feature)\n",
    "                labels.append(folder)\n",
    "    return np.array(features) , np.array(labels)\n",
    "\n",
    "x,Y = load_dataset('/Users/khushpatel/Desktop/ML Projects/Emotion Detection/TESS Toronto emotional speech set data')\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and labels have been saved to audio_features.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(x)\n",
    "df['label'] = Y\n",
    "df.to_csv('audio_features.csv', index=False)\n",
    "\n",
    "print(\"Features and labels have been saved to audio_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       YAF_disgust\n",
       "1       YAF_disgust\n",
       "2       YAF_disgust\n",
       "3       YAF_disgust\n",
       "4       YAF_disgust\n",
       "           ...     \n",
       "2795        OAF_Sad\n",
       "2796        OAF_Sad\n",
       "2797        OAF_Sad\n",
       "2798        OAF_Sad\n",
       "2799        OAF_Sad\n",
       "Name: label, Length: 2800, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.drop(columns=['label'])\n",
    "x\n",
    "y=df['label']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=785\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "file_path = '/Users/khushpatel/Downloads/1001_DFA_ANG_XX.wav'\n",
    "feature = extract_feature(file_path,sample_rate=22050)\n",
    "features.append(feature)\n",
    "x = np.array(features)\n",
    "df = pd.DataFrame(x)\n",
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
